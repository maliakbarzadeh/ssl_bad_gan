# ูุณุชูุฏุงุช ูุฏู GAN ุจุฑุง ุฏุชุงุณุช Two Circles

## ๐ ุชูุถุญุงุช ฺฉู

ุงู ูพุฑูฺู ฺฉ ูุฏู **Semi-Supervised GAN** ุจุฑุง ุงุฏฺฏุฑ ุชูุฒุน ุฏุงุฏูโูุง ุฏู ุฏุงุฑู ูุชุญุฏุงููุฑฺฉุฒ (Two Circles) ุงุณุช. ุงู ูุฏู ุงุฒ ุชุนุฏุงุฏ ูุญุฏูุฏ ุฏุงุฏู ุจุฑฺุณุจโุฏุงุฑ ู ุชุนุฏุงุฏ ุฒุงุฏ ุฏุงุฏู ุจุฏูู ุจุฑฺุณุจ ุจุฑุง ุขููุฒุด ุงุณุชูุงุฏู ูโฺฉูุฏ.

### โญ ูฺฺฏ ฺฉูุฏ: ุดูุงุณุง ุฏุงุฏูโูุง Fake ุจู ุนููุงู ฺฉูุงุณ ุฌุฏุงฺฏุงูู

ุทุจู ููุงูู **"Improved Techniques for Training GANs"** (Salimans et al., 2016)ุ Discriminator ุจู ุฌุง ุงูฺฉู ููุท ุฏุงุฏูโูุง ูุงูุน ู ุชููุฏ ุฑุง ุชูฺฉฺฉ ฺฉูุฏุ ุงุฒ ฺฉ ูุนูุงุฑ **K+1 ฺฉูุงุณู** ุงุณุชูุงุฏู ูโฺฉูุฏ:

- **K ฺฉูุงุณ**: ุจุฑุง ุฏุงุฏูโูุง ูุงูุน (ุฏุงุฑู ุฏุงุฎู ู ุจุฑูู)
- **1 ฺฉูุงุณ ุงุถุงู**: ุจุฑุง ุดูุงุณุง ุฏุงุฏูโูุง ุชููุฏ (Fake)

ุงู ุฑูุด ุจุงุนุซ ูโุดูุฏ:
1. โ Discriminator ุฏุงุฏูโูุง ุชููุฏ ุฑุง ุจู ุนููุงู ฺฉูุงุณ ุฌุฏุงฺฏุงูู ุดูุงุณุง ฺฉูุฏ
2. โ Generator ูุฌุจูุฑ ุดูุฏ ุฏุงุฏูโูุง ุชููุฏ ฺฉูุฏ ฺฉู ุฏุฑ ูุฑุฒ ุจู ฺฉูุงุณโูุง ูุงูุน ูุฑุงุฑ ฺฏุฑูุฏ
3. โ ููโูพูุดุงู ฺฉูุชุฑ ุจุง ุฏุงุฏูโูุง ูุงูุน ุฏุงุดุชู ุจุงุดูุฏ

## ๐ฏ ูุฏู

- **ุงุฏฺฏุฑ ุชูุฒุน ุฏุงุฏู**: ูุฏู ุจุงุฏ ุจุชูุงูุฏ ููุงุท 2D ุฑุง ุฏุฑ ุงูฺฏู ุฏู ุฏุงุฑู ูุชุญุฏุงููุฑฺฉุฒ ุชููุฏ ฺฉูุฏ
- **ุทุจููโุจูุฏ ุจุง ุฏุงุฏู ฺฉู**: ุจุง ุงุณุชูุงุฏู ุงุฒ ุชููุง 40 ููููู ุจุฑฺุณุจโุฏุงุฑ (20 ููููู ุจุฑุง ูุฑ ฺฉูุงุณ)
- **ุงุณุชูุงุฏู ุงุฒ ุฏุงุฏู ุจุฏูู ุจุฑฺุณุจ**: ุจุฑุง ุจูุจูุฏ ุนููฺฉุฑุฏ ุงุฒ 2000 ููููู ุจุฏูู ุจุฑฺุณุจ ุงุณุชูุงุฏู ูโุดูุฏ

## ๐๏ธ ุณุงุฎุชุงุฑ ูุงูโูุง

### ูุงูโูุง ุงุตู
- **`two_circles_trainer.py`**: ูุงู ุงุตู ุขููุฒุด ูุฏู
- **`two_circles_model.py`**: ูุนูุงุฑ ุดุจฺฉูโูุง ุนุตุจ (Generator, Discriminator, Encoder)
- **`data.py`**: ุจุงุฑฺฏุฐุงุฑ ู ูุฏุฑุช ุฏุชุงุณุช
- **`config.py`**: ุชูุธูุงุช ู ูพุงุฑุงูุชุฑูุง ูุฏู
- **`utils.py`**: ุชูุงุจุน ฺฉูฺฉ (log_sum_exp, entropy, ู ุบุฑู)

### ูุงูโูุง ุฎุฑูุฌ
- **`two_circles_log/`**: ูพูุดู ุดุงูู ูุงฺฏโูุง ู ุชุตุงูุฑ
  - `two_circles.FM+PT+ENT.run0.txt`: ูุงู ูุงฺฏ ุขููุฒุด
  - `two_circles.FM+PT+Ent.run0.png`: ุชุตูุฑ ุณุงุฏู (Real vs Generated)
  - `two_circles.detailed.iter_*.png`: ุชุตุงูุฑ ุฏูู ุจุง ูพุดโุจูโูุง discriminator

## โ๏ธ ูพุงุฑุงูุชุฑูุง ูุฏู

### ุชูุธูุงุช ุฏุชุงุณุช
```python
dataset = 'two_circles'
n_samples = 2000              # ุชุนุฏุงุฏ ฺฉู ูููููโูุง
noise_level = 0.05            # ูุฒุงู ููุฒ ุฏุฑ ุฏุงุฏูโูุง
factor = 0.5                  # ูุณุจุช ุดุนุงุน ุฏุงุฑู ุฏุงุฎู ุจู ุจุฑูู
size_labeled_data = 40        # ุชุนุฏุงุฏ ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑ (20 ููููู ุงุฒ ูุฑ ฺฉูุงุณ)
```

### ุชูุธูุงุช ุดุจฺฉู
```python
image_size = 2                # ุงุจุนุงุฏ ูุฑูุฏ (x, y)
num_label = 2                 # ุชุนุฏุงุฏ ฺฉูุงุณโูุง ูุงูุน (ุฏุงุฑู ุฏุงุฎู ู ุจุฑูู)
num_classes = 3               # ฺฉู ฺฉูุงุณโูุง ุดุงูู Fake (inner=0, outer=1, fake=2)
noise_size = 20               # ุงุจุนุงุฏ ูุถุง latent ุจุฑุง Generator
```

### ุชูุธูุงุช ุขููุฒุด
```python
max_epochs = 5000             # ุญุฏุงฺฉุซุฑ ุชุนุฏุงุฏ epoch
train_batch_size = 32         # ุงูุฏุงุฒู batch ุจุฑุง ุขููุฒุด
dis_lr = 0.003               # learning rate ุจุฑุง Discriminator
gen_lr = 0.001               # learning rate ุจุฑุง Generator
```

### ูพุงุฑุงูุชุฑูุง Loss
```python
ent_weight = 0.1             # ูุฒู Conditional Entropy Loss
cond_ent_weight = 0.1        # ูุฒู Conditional Entropy (ุงุฒ ููุงูู Bad GAN)
fm_weight = 1.0              # ูุฒู Feature Matching Loss
pt_weight = 0.5              # ูุฒู Pull-away Term Loss
density_weight = 0.5         # ูุฒู Density-based loss (complement generator)
vi_weight = 0.1              # ูุฒู VI entropy loss
```

### ูุนุงู/ุบุฑูุนุงู ฺฉุฑุฏู ุชฺฉูฺฉโูุง (ุงุฒ ููุงูู Bad GAN)
```python
# ุชฺฉูฺฉโูุง ุงุตู ููุงูู (ููู ูพุดโูุฑุถ ูุนุงู ูุณุชูุฏ)
use_conditional_entropy = True  # ุงุณุชูุงุฏู ุงุฒ Conditional Entropy
use_feature_matching = True     # ุงุณุชูุงุฏู ุงุฒ Feature Matching
use_pull_away = True            # ุงุณุชูุงุฏู ุงุฒ Pull-away Term

# ุชฺฉูฺฉโูุง ูพุดุฑูุชู (ุงุฎุชุงุฑ - ูพุดโูุฑุถ ุบุฑูุนุงู)
use_complement_generator = False  # ุงุณุชูุงุฏู ุงุฒ Complement Generator ุจุง KDE
use_vi_entropy = False            # ุงุณุชูุงุฏู ุงุฒ Variational Inference entropy

# ูพุงุฑุงูุชุฑูุง ุงุถุงู ุจุฑุง ุชฺฉูฺฉโูุง ูพุดุฑูุชู
density_threshold = 0.05     # ุขุณุชุงูู ฺฺฏุงู ุจุฑุง complement generator
```

**ูฺฉุชู**: ุดูุง ูโุชูุงูุฏ ูุฑ ฺฉ ุงุฒ ุงู ุชฺฉูฺฉโูุง ุฑุง ูุนุงู/ุบุฑูุนุงู ฺฉูุฏ ุชุง ุชุฃุซุฑ ุขูโูุง ุฑุง ูุดุงูุฏู ฺฉูุฏ.

**โ๏ธ ูุดุฏุงุฑ**: ูุนุงู ฺฉุฑุฏู ููุฒูุงู ููู ุชฺฉูฺฉโูุง ููฺฉู ุงุณุช training ุฑุง ูพฺุฏู ฺฉูุฏ. ุชูุตู ูโุดูุฏ ุงูู ุจุง ุชฺฉูฺฉโูุง ุงุตู ุดุฑูุน ฺฉูุฏ.

### ุชูุธูุงุช ููุงุด
```python
eval_period = 200            # ูุฑ 200 iteration ุงุฑุฒุงุจ ุงูุฌุงู ุดูุฏ
vis_period = 100             # ูุฑ 100 iteration ุชุตูุฑ ุณุงุฏู ุฐุฎุฑู ุดูุฏ
plot_period = 50             # ูุฑ 50 iteration ุชุตูุฑ ุฏูู ุฐุฎุฑู ุดูุฏ
```

## ๐๏ธ ูุนูุงุฑ ูุฏู

### 1. Discriminator (ูุชูุงุฒฺฉููุฏู)
```
Input (2D) โ Linear(2, 128) โ ReLU โ Dropout(0.3)
           โ Linear(128, 128) โ ReLU โ Dropout(0.3)
           โ Linear(128, 128) โ ReLU
           โ Linear(128, 3) โ Output (3 Logits)
```

**ุฎุฑูุฌ**: 3 ฺฉูุงุณ
- **ฺฉูุงุณ 0**: ุฏุงุฑู ุฏุงุฎู (Inner Circle)
- **ฺฉูุงุณ 1**: ุฏุงุฑู ุจุฑูู (Outer Circle)
- **ฺฉูุงุณ 2**: ุฏุงุฏู ุชููุฏ (Fake/Generated)

**ููุด**: 
- ุชุดุฎุต ุฏุงุฏู ูุงูุน ุงุฒ ุฏุงุฏู ุชููุฏ
- ุทุจููโุจูุฏ ุฏุงุฏูโูุง ูุงูุน ุจู ุฏุงุฑู ุฏุงุฎู (0) ุง ุจุฑูู (1)
- ุดูุงุณุง ุฏุงุฏูโูุง ุชููุฏ ุจู ุนููุงู ฺฉูุงุณ ุฌุฏุงฺฏุงูู (2)

### 2. Generator (ุชููุฏฺฉููุฏู)
```
Input (Noise: 20D) โ Linear(20, 128) โ BatchNorm โ ReLU
                   โ Linear(128, 128) โ BatchNorm โ ReLU
                   โ Linear(128, 2) โ Tanh โ Output (2D)
```

**ููุด**: ุชููุฏ ููุงุท 2D ุฌุฏุฏ ฺฉู ุดุจู ุชูุฒุน ุฏู ุฏุงุฑู ุจุงุดูุฏ

### 3. Encoder (ฺฉุฏฺฏุฐุงุฑ) - ุจุฑุง Variational Inference
```
Input (2D) โ Linear(2, 128) โ BatchNorm โ ReLU
           โ Linear(128, 128) โ BatchNorm โ ReLU
           โ Linear(128, 40) โ Output (mu + log_sigma)
```

**ุฎุฑูุฌ**: 
- **Mode ุนุงุฏ**: ููุท latent vector (20D)
- **Mode Variational**: mu (20D) + log_sigma (20D) = 40D

**ููุด**: 
- ูฺฏุงุดุช ููุงุท 2D ุจู ูุถุง latent
- ูุญุงุณุจู ุชูุฒุน ุงุญุชูุงู q(z|x) ุจุฑุง Variational Inference
- ุงุณุชูุงุฏู ุฏุฑ VI-based entropy maximization

## ๐ ุชูุงุจุน Loss

ุงู ูพุงุฏูโุณุงุฒ ุงุฒ ุฑูุด **"Bad GAN"** (Dai et al., NIPS 2017) ุงุณุชูุงุฏู ูโฺฉูุฏ. ุจุฑ ุฎูุงู GAN ูุนูููุ ูุฏู ุงู ูุณุช ฺฉู Generator ฺฉุงูู ุจุงุดุฏุ ุจูฺฉู ุจุงุฏ ูููููโูุง ุฏุฑ **ููุงุทู ฺฉูโุชุฑุงฺฉู** (ูุฑุฒูุง ุจู ฺฉูุงุณโูุง) ุชููุฏ ฺฉูุฏ.

### 1. Supervised Loss (Classification)
```python
lab_loss = CrossEntropyLoss(predictions[:, :K], true_labels)
```
ูุญุงุณุจู ูโุดูุฏ ููุท ุฑู **ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑ** ู ููุท ุจุง ุงุณุชูุงุฏู ุงุฒ **K ฺฉูุงุณ ูุงูุน** (ฺฉูุงุณ Fake ุงุณุชูุงุฏู ููโุดูุฏ)

### 2. Unsupervised Loss (GAN)

#### ุงูู) Real Data Loss
```python
unl_logsumexp = log_sum_exp(unl_logits[:, :K])  # ููุท ุฑู K ฺฉูุงุณ ูุงูุน
true_loss = -mean(unl_logsumexp) + mean(softplus(unl_logsumexp))
```
ุฏุงุฏูโูุง ูุงูุน ูุจุงุฏ ุจู ฺฉูุงุณ Fake ูุณุจุช ุฏุงุฏู ุดููุฏ

#### ุจ) Fake Data Loss
```python
fake_loss = CrossEntropyLoss(gen_logits, fake_class_label)  # Label = K
```
ุฏุงุฏูโูุง ุชููุฏ **ุจุงุฏ** ุจู ฺฉูุงุณ K (Fake) ูุณุจุช ุฏุงุฏู ุดููุฏ

### 3. ๐ Conditional Entropy Loss (ฺฉูุฏ ุงุฒ ููุงูู Bad GAN)
```python
# ูุญุงุณุจู ุงุญุชูุงูุงุช ููุท ุฑู K ฺฉูุงุณ ูุงูุน
unl_probs = softmax(unl_logits[:, :K])

# Conditional Entropy: -sum p(k|x) log p(k|x)
cond_ent_loss = -mean(sum(unl_probs * log(unl_probs)))

# ุจู loss discriminator ุงุถุงูู ูโุดูุฏ (ุจุฑุง minimization)
d_loss += cond_ent_weight * cond_ent_loss
```

**ฺุฑุง ููู ุงุณุชุ**
- ุจุงุนุซ ูโุดูุฏ Discriminator ุฑู ุฏุงุฏูโูุง ุจุฏูู ุจุฑฺุณุจ **ุจุง ุงุทููุงู ุจุงูุง** ูพุดโุจู ฺฉูุฏ
- ุฌูู "uncertain predictions" ุฑุง ูโฺฏุฑุฏ
- ุทุจู ููุงููุ ุงู ุดุฑุท ูุงุฒู ุงุณุช: **"Strong True-Fake Belief"**
- ุจุฏูู ุงู lossุ discriminator ููฺฉู ุงุณุช ุงุญุชูุงูุงุช ฺฉุณุงู ุจู ููู ฺฉูุงุณโูุง ุจุฏูุฏ

**ูุงุจู ูุนุงู/ุบุฑูุนุงู**: ุจุง `use_conditional_entropy` ุฏุฑ config

### 4. Feature Matching Loss
```python
real_features = discriminator.get_features(real_data)  # layer ูุจู ุงุฒ output
gen_features = discriminator.get_features(fake_data)
fm_loss = mean(|mean(gen_features) - mean(real_features)|)
```
Generator ุชูุงุด ูโฺฉูุฏ ุฏุงุฏูโูุง ุชููุฏ ฺฉูุฏ ฺฉู **ุขูุงุฑูุง feature** ุขูโูุง ุดุจู ุฏุงุฏูโูุง ูุงูุน ุจุงุดุฏ

**ูุงุจู ูุนุงู/ุบุฑูุนุงู**: ุจุง `use_feature_matching` ุฏุฑ config  
**ูุฒู**: `fm_weight` ุฏุฑ config (ูพุดโูุฑุถ: 1.0)

### 5. Pull-away Term Loss
```python
normalized = gen_features / ||gen_features||
cosine_similarity = normalized @ normalized.T
pt_loss = pt_weight * sum((cosine_similarity * mask)ยฒ) / (n * (n-1))
```
ุจุงุนุซ **ุชููุน** ุฏุฑ ุฏุงุฏูโูุง ุชููุฏ ูโุดูุฏ ู ุงุฒ **mode collapse** ุฌููฺฏุฑ ูโฺฉูุฏ

**ูุงุจู ูุนุงู/ุบุฑูุนุงู**: ุจุง `use_pull_away` ุฏุฑ config  
**ูุฒู**: `pt_weight` ุฏุฑ config (ูพุดโูุฑุถ: 0.5)

### 6. ๐ฌ Density-based Complement Loss (ูพุดุฑูุชู)
```python
# ุงุณุชูุงุฏู ุงุฒ Kernel Density Estimation (KDE)
log_density = kde_model.score_samples(gen_samples)

# ุฑูุด 1: Minimize density ูุณุชูู
density_loss = -density_weight * mean(log_density)

# ุฑูุด 2 (ูพุงุฏูโุณุงุฒ ุดุฏู): Hinge loss
density_loss = density_weight * mean(ReLU(log_density - threshold))
```

**ูุฏู**: Generator ุจุงุฏ ุฏุฑ ููุงุทู **ฺฉูโุชุฑุงฺฉู** ุชููุฏ ฺฉูุฏ (complement generator)

**ูุญูู ฺฉุงุฑ**:
1. **KDE** ฺฺฏุงู ุงุญุชูุงู ุฏุงุฏูโูุง ูุงูุน ุฑุง ุงุฏ ูโฺฏุฑุฏ: `p(x)`
2. Generator ุชูุงุด ูโฺฉูุฏ ูููููโูุง ุจุง ฺฺฏุงู **ูพุงู** ุชููุฏ ฺฉูุฏ
3. ุงู ูููููโูุง ูุนูููุงู ุฏุฑ **ูุฑุฒูุง ุจู ฺฉูุงุณโูุง** ูุฑุงุฑ ูโฺฏุฑูุฏ
4. Hinge loss: ููุท ููุช ฺฺฏุงู ุงุฒ threshold ุจุดุชุฑ ุดุฏุ ุฌุฑูู ูโุดูุฏ

**ูุฒุงุง**:
- โ ุชุถูู ูโฺฉูุฏ Generator ุฑู ุฏุงุฏูโูุง ูุงูุน overlap ูุฏุงุดุชู ุจุงุดุฏ
- โ ูููููโูุง ุชููุฏ ุฏุฑ ููุงุทู ููุฏ ุจุฑุง SSL ูุฑุงุฑ ูโฺฏุฑูุฏ
- โ ูุณุชููุงู ูุฏู ููุงูู "Bad GAN" ุฑุง ูพุงุฏูโุณุงุฒ ูโฺฉูุฏ

**ูุงุจู ูุนุงู/ุบุฑูุนุงู**: `use_complement_generator = True`  
**ูพุงุฑุงูุชุฑูุง**: 
- `density_weight` (ูพุดโูุฑุถ: 0.5)
- `density_threshold` (ูพุดโูุฑุถ: 0.05)
- `bandwidth` ุจุฑุง KDE (ูพุดโูุฑุถ: 0.1)

**ุชูุฌู**: KDE ุฏุฑ `__init__` ุฑู ุฏุงุฏูโูุง ูุงูุน ุขููุฒุด ูโุจูุฏ (ฺฉุจุงุฑ)

### 7. ๐งฌ VI-based Entropy Maximization (ูพุดุฑูุชู)
```python
# Encode generated samples: x โ (mu, log_sigma)
mu, log_sigma = encoder(gen_images)

# KL divergence from prior N(0,I)
KL(q(z|x) || N(0,I)) = -0.5 * sum(1 + 2*log_sigma - muยฒ - exp(2*log_sigma))

# ุง Direct entropy maximization:
H(q(z|x)) = sum(log_sigma) + const

vi_loss = vi_weight * mean(KL_divergence)
```

**ูุฏู**: ุงูุฒุงุด **ุชููุน ุฏุฑ latent space** โ coverage ุจูุชุฑ ุงุฒ data manifold

**ูุญูู ฺฉุงุฑ**:
1. **Encoder** ุฏุงุฏู ุชููุฏ ุฑุง ุจู latent space ูฺฏุงุดุช ูโฺฉูุฏ: `x โ q(z|x)`
2. ูุญุงุณุจู ุชูุฒุน ุงุญุชูุงู ุจุง **mu** ู **sigma**
3. **KL divergence**: ุงุทููุงู ุงุฒ ุงูฺฉู ุชูุฒุน ุงุฒ prior N(0,I) ุฎู ุฏูุฑ ูุณุช
4. ฺฉู ฺฉุฑุฏู KL = ุงูุฒุงุด entropy = ุชููุน ุจุดุชุฑ

**ูุฒุงุง**:
- โ ุชููุน ุฏุฑ latent space โ ุชููุน ุฏุฑ generated samples
- โ ุฌููฺฏุฑ ุงุฒ mode collapse ุฏุฑ ุณุทุญ latent
- โ Coverage ุจูุชุฑ ุงุฒ distribution ูุงูุน

**ุชูุงูุช ุจุง Pull-away Term**:
| ุฑูุด | ูุญู ุงุนูุงู | ุชุฃุซุฑ |
|-----|-----------|-------|
| Pull-away Term | Feature space (discriminator) | ุชููุน ุฏุฑ features |
| VI Entropy | Latent space (z) | ุชููุน ุฏุฑ latent code |

**ูุงุจู ูุนุงู/ุบุฑูุนุงู**: `use_vi_entropy = True`  
**ูพุงุฑุงูุชุฑูุง**: 
- `vi_weight` (ูพุดโูุฑุถ: 0.1)
- Encoder ุจุงุฏ ุจุง `output_params=True` ุขููุฒุด ุจุจูุฏ

**ุชูุฌู**: Encoder ููุฑุงู ุจุง Generator ุขููุฒุด ูโุจูุฏ (joint training)

### 8. ุชฺฉูฺฉโูุง ูพุดุฑูุชู - ุฎูุงุตู

| ุชฺฉูฺฉ | ูุถุนุช | ูพุดโูุฑุถ | ูพฺุฏฺฏ | ุชูุตู |
|--------|--------|---------|---------|-------|
| **Conditional Entropy** | โ ูพุงุฏูโุณุงุฒ ุดุฏู | ูุนุงู | ฺฉู | **ุญุชูุงู** ุงุณุชูุงุฏู ฺฉู |
| **Feature Matching** | โ ูพุงุฏูโุณุงุฒ ุดุฏู | ูุนุงู | ฺฉู | ุชูุตู ูโุดูุฏ |
| **Pull-away Term** | โ ูพุงุฏูโุณุงุฒ ุดุฏู | ูุนุงู | ูุชูุณุท | ุจุฑุง ุชููุน ููุฏ ุงุณุช |
| **Density-based (KDE)** | โ ูพุงุฏูโุณุงุฒ ุดุฏู | ุบุฑูุนุงู | ูุชูุณุท | ุจุฑุง complement generator |
| **VI Entropy** | โ ูพุงุฏูโุณุงุฒ ุดุฏู | ุบุฑูุนุงู | ุจุงูุง | ุจุฑุง ุชููุน ุจุดุชุฑ |
| **PixelCNN Density** | โธ๏ธ ูุงุจู ุงุณุชูุงุฏู | ุบุฑูุนุงู | ุฎู ุจุงูุง | ููุท ุจุฑุง images |

### Loss Function ฺฉุงูู

**Discriminator Loss**:
```python
d_loss = lab_loss                                    # supervised
       + unl_loss (true_loss + fake_loss)           # unsupervised GAN
       + cond_ent_weight * cond_ent_loss            # conditional entropy
```

**Generator Loss** (ูุงุจู ุชูุธู):
```python
g_loss = 0

# ุชฺฉูฺฉโูุง ุงุตู (ุชูุตู ูโุดูุฏ)
if use_feature_matching:
    g_loss += fm_weight * fm_loss                    # feature matching (1.0)
    
if use_pull_away:
    g_loss += pt_weight * pt_loss                    # pull-away term (0.5)

# ุชฺฉูฺฉโูุง ูพุดุฑูุชู (ุงุฎุชุงุฑ)
if use_complement_generator:
    g_loss += density_weight * density_loss          # KDE-based complement (0.5)
    
if use_vi_entropy:
    g_loss += vi_weight * vi_loss                    # VI entropy (0.1)
```

**ูุซุงู ุชุฑฺฉุจโูุง ูุฎุชูู**:
```python
# ูพุงู (ููุท FM + PT)
g_loss = 1.0*fm_loss + 0.5*pt_loss

# ุจุง Complement Generator
g_loss = 1.0*fm_loss + 0.5*pt_loss + 0.5*density_loss

# ฺฉุงูู (ููู ุชฺฉูฺฉโูุง)
g_loss = 1.0*fm_loss + 0.5*pt_loss + 0.5*density_loss + 0.1*vi_loss
```

## ๐จ ูููุฏุงุฑูุง ู ุชุตุงูุฑ ุฎุฑูุฌ

### ุชุตูุฑ ุณุงุฏู (ูุฑ 100 iteration)
**ูุงู**: `two_circles.FM+PT+Ent.run0.png`

ุฏู ูููุฏุงุฑ ุฌูุจ ูู:
- **ุณูุช ฺูพ - ุฏุงุฏู ูุงูุน**:
  - โช ุฎุงฺฉุณุชุฑ: ุฏุงุฏูโูุง ูุงูุน (ุจุฏูู ุชูฺฉฺฉ ุจุฑฺุณุจ)
  
- **ุณูุช ุฑุงุณุช - ุฏุงุฏู ุชููุฏ**:
  - ๐ด ูุฑูุฒ: ุฏุงุฏูโูุง ุชููุฏ ุดุฏู ุชูุณุท Generator

### ุชุตูุฑ ุฏูู (ูุฑ 50 iteration)
**ูุงู**: `two_circles.detailed.iter_XXX.png`

ุฏู ูููุฏุงุฑ ุฌูุจ ูู ุจุง ุฌุฒุฆุงุช ฺฉุงูู:

#### ูููุฏุงุฑ ุณูุช ฺูพ: Ground Truth (ูุงูุนุช)
| ุฑูฺฏ | ููุน ุฏุงุฏู | ุชูุถุญุงุช |
|-----|---------|---------|
| ๐ต ุขุจ | ุฏุงุฏู ุจุฑฺุณุจโุฏุงุฑ ุฏุงุฑู ุฏุงุฎู | ุฏุงุฑู ูพุฑ ุจุง border ูุดฺฉ |
| ๐ ูุงุฑูุฌ | ุฏุงุฏู ุจุฑฺุณุจโุฏุงุฑ ุฏุงุฑู ุจุฑูู | ุฏุงุฑู ูพุฑ ุจุง border ูุดฺฉ |
| โช ุฎุงฺฉุณุชุฑ | ุฏุงุฏู ุจุฏูู ุจุฑฺุณุจ | ููุงุท ฺฉูฺฺฉ ุจุฏูู border |
| ๐ด ูุฑูุฒ | ุฏุงุฏู ุชููุฏ | ููุงุท ฺฉูฺฺฉ ุจุฏูู border |

#### ูููุฏุงุฑ ุณูุช ุฑุงุณุช: Discriminator Predictions (ูพุดโุจูโูุง)
| ุฑูฺฏ | ููุน ุฏุงุฏู | ุชูุถุญุงุช |
|-----|---------|---------|
| ๐ข ุณุจุฒ | ุฏุงุฏู ุจุฑฺุณุจโุฏุงุฑ ุตุญุญ | ูพุดโุจู ุฏุฑุณุช - ุฏุงุฑู ุจุง border ูุดฺฉ |
| โ ูุฑูุฒ | ุฏุงุฏู ุจุฑฺุณุจโุฏุงุฑ ุงุดุชุจุงู | ูพุดโุจู ุบูุท - ุนูุงูุช X ุจุฒุฑฺฏ |
| ๐ท ุขุจ ุฑูุดู | ุฏุงุฏู ุจุฏูู ุจุฑฺุณุจ (ูพุดโุจู: ุฏุงุฎู) | Discriminator ุขู ุฑุง ฺฉูุงุณ 0 ุชุดุฎุต ุฏุงุฏู |
| ๐ก ฺฏูุฏู | ุฏุงุฏู ุจุฏูู ุจุฑฺุณุจ (ูพุดโุจู: ุจุฑูู) | Discriminator ุขู ุฑุง ฺฉูุงุณ 1 ุชุดุฎุต ุฏุงุฏู |
| ๏ฟฝ ุจููุด | ุฏุงุฏู ุจุฏูู ุจุฑฺุณุจ (ูพุดโุจู: Fake) | Discriminator ุงุดุชุจุงูุงู ุขู ุฑุง Fake ุชุดุฎุต ุฏุงุฏู! |
| ๐น ุขุจ ุชุฑู | ุฏุงุฏู ุชููุฏ (ูพุดโุจู: ุฏุงุฎู) | **ุงุดุชุจุงู** - ูุจุงุฏ ุจู ฺฉูุงุณ ูุงูุน ูุณุจุช ุฏุงุฏู ุดูุฏ |
| ๐ ูุงุฑูุฌ ุชุฑู | ุฏุงุฏู ุชููุฏ (ูพุดโุจู: ุจุฑูู) | **ุงุดุชุจุงู** - ูุจุงุฏ ุจู ฺฉูุงุณ ูุงูุน ูุณุจุช ุฏุงุฏู ุดูุฏ |
| โญ ุณุจุฒ ููู | ุฏุงุฏู ุชููุฏ (ูพุดโุจู: Fake) | **ุตุญุญ** - ุจู ุฏุฑุณุช ุจู ฺฉูุงุณ Fake ูุณุจุช ุฏุงุฏู ุดุฏู (ุณุชุงุฑู) |

**ุนููุงู ูููุฏุงุฑ ุฑุงุณุช ุดุงูู**:
- ุดูุงุฑู Iteration
- ุฏูุช ุฑู ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑ: `XX.X% (ุชุนุฏุงุฏ ุตุญุญ / ฺฉู)`
- ูุฑุฎ ุชุดุฎุต Fake: `XX.X%` (ุฏุฑุตุฏ ุฏุงุฏูโูุง ุชููุฏ ฺฉู ุจู ุฏุฑุณุช ุจู ฺฉูุงุณ Fake ูุณุจุช ุฏุงุฏู ุดุฏูโุงูุฏ)

## ๐ ุฎุฑูุฌ ูุงฺฏ

ูุงู ูุงฺฏ ุดุงูู ุงุทูุงุนุงุช ุฒุฑ ุงุณุช:

### ุงุทูุงุนุงุช ุงููู
```
Using device: cuda
GPU: NVIDIA GeForce RTX 3080
seed : 13
dataset : two_circles
...
```

### ุงุทูุงุนุงุช ูุฑ Iteration ุงุฑุฒุงุจ (ูุฑ 200 iteration)
```
#200    train: 0.1234, 0.0250 | dev: 0.1567, 0.0300 | best: 0.0300
        | lab acc: 0.9500 | unl acc: 0.8500 | gen acc: 0.7200
        | lab loss: 0.2100 | unl loss: 0.3400 | ent loss: 0.0120
        | fm loss: 0.0450 | pt loss: 0.0023
        | [Eval] unl acc: 0.8900, gen acc: 0.7500, max unl acc: 0.9200, max gen acc: 0.7800
        | lr: 0.00300
```

**ุดุฑุญ ูพุงุฑุงูุชุฑูุง**:
- `train`: loss ู error rate ุฑู ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑ
- `dev`: loss ู error rate ุฑู ุฏุงุฏูโูุง ุชุณุช
- `best`: ุจูุชุฑู error rate ุชุงฺฉููู
- `lab acc`: ุฏูุช ุทุจููโุจูุฏ ุฑู ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑ (ุจุงุฏ ูุฒุฏฺฉ 1 ุจุงุดุฏ)
- `unl acc`: ุฏุฑุตุฏ ุฏุงุฏูโูุง ูุงูุน ฺฉู ุจู ฺฉูุงุณโูุง ูุงูุน (0 ุง 1) ูุณุจุช ุฏุงุฏู ุดุฏูโุงูุฏ (ูู Fake)
- `gen acc`: **ุฏุฑุตุฏ ุฏุงุฏูโูุง ุชููุฏ ฺฉู ุจู ุฏุฑุณุช ุจู ฺฉูุงุณ Fake ูุณุจุช ุฏุงุฏู ุดุฏูโุงูุฏ** (ุจุงุฏ ุจู 1 ูุฒุฏฺฉ ุดูุฏ)
- `lab loss`: Classification loss
- `unl loss`: GAN loss (ุดุงูู true_loss ู fake_loss)
- `ent loss`: Entropy loss (ุงุฒ ููุงูู ูุจู)
- `cond_ent_loss`: **Conditional Entropy loss** (ฺฉูุฏ ุงุฒ ููุงูู Bad GAN)
- `fm loss`: Feature Matching loss
- `pt loss`: Pull-away Term loss
- `density loss`: **Density-based complement loss** (ุงุฎุชุงุฑ - ุงุฒ KDE)
- `vi loss`: **VI-based entropy loss** (ุงุฎุชุงุฑ - ุงุฒ Encoder)
- `lr`: Learning rate ูุนู

### ุงุทูุงุนุงุช ูฺูุงูุฒุดู (ูุฑ 50 iteration)
```
[Visualization 50] Labeled Data Accuracy: 87.50%
[Visualization 100] Labeled Data Accuracy: 92.50%
[Visualization 150] Labeled Data Accuracy: 95.00%
```

## ๐ ูุญูู ุงุฌุฑุง

### 1. ูุนุงูโุณุงุฒ ูุญุท ูุฌุงุฒ
```powershell
cd D:\GAN\ssl_bad_gan
..\venv3.12\Scripts\Activate.ps1
```

### 2. ุงุฌุฑุง ุขููุฒุด
```powershell
python two_circles_trainer.py -suffix run0
```

### 3. ูพุงุฑุงูุชุฑูุง ุงุฎุชุงุฑ
```powershell
python two_circles_trainer.py -suffix run1
```
`-suffix`: ุดูุงุณู ุจุฑุง ุชูุงุฒ ุจู ุงุฌุฑุงูุง ูุฎุชูู

## ๐ป ูุงุฒููุฏโูุง ุณุฎุชโุงูุฒุงุฑ

- **GPU**: ุงุฎุชุงุฑ (ฺฉุฏ ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ GPU ุง CPU ุฑุง ุชุดุฎุต ูโุฏูุฏ)
- **RAM**: ุญุฏุงูู 4GB
- **ูุถุง ุฏุณฺฉ**: ุญุฏูุฏ 100MB ุจุฑุง ุฐุฎุฑู ุชุตุงูุฑ ู ูุงฺฏโูุง

## ๐ฆ ฺฉุชุงุจุฎุงููโูุง ููุฑุฏ ูุงุฒ

```
torch >= 1.8.0
torchvision
numpy
matplotlib
scikit-learn      # ุจุฑุง KDE (Kernel Density Estimation)
```

**ุชูุฌู**: ุจุฑุง ุชฺฉูฺฉโูุง ูพุดุฑูุชู:
- **KDE-based complement generator**: ูุงุฒ ุจู `scikit-learn` ุฏุงุฑุฏ (ุงุฒ ูุจู ูุตุจ ุงุณุช)
- **VI-based entropy**: ููุท ุงุฒ ุดุจฺฉูโูุง ููุฌูุฏ ุงุณุชูุงุฏู ูโฺฉูุฏ (ูุงุฒ ุจู ฺฉุชุงุจุฎุงูู ุงุถุงู ูุฏุงุฑุฏ)

## ๐ ูฺฉุงุช ููู

### 1. ููุงูู Bad GAN ฺุณุชุ
**"Good Semi-supervised Learning That Requires a Bad GAN"** (Dai et al., NIPS 2017)

**ุงุฏู ุงุตู**: ฺฉ Generator ุนุงู ฺฉู ุฏููุงู ูุงููุฏ ุฏุงุฏู ูุงูุน ุชููุฏ ูโฺฉูุฏุ ุจุฑุง Semi-Supervised Learning ููุฏ **ูุณุช**! ฺุฑุงุ

- ุงฺฏุฑ Generator ฺฉุงูู ุจุงุดุฏ: `p_G(x) = p(x)`
- ุนู ุฏุงุฏู ุชููุฏ ุฏููุงู ูุซู ูุงูุน ุงุณุช
- Discriminator ููโุชูุงูุฏ ุขูโูุง ุฑุง ุชุดุฎุต ุฏูุฏ
- Semi-Supervised Learning ูุงุฏูโุง ูุฏุงุฑุฏ (ููุท ูุซู Supervised ูุนููู ูโุดูุฏ)

**ุฑุงูโุญู**: ูุง ุจู ฺฉ **"Complement Generator"** ูุงุฒ ุฏุงุฑู ฺฉู:
- ูููููโูุง ุฏุฑ **ููุงุทู ฺฉูโุชุฑุงฺฉู** ุชููุฏ ฺฉูุฏ
- ุงู ููุงุทู ูุนูููุงู **ูุฑุฒูุง ุจู ฺฉูุงุณโูุง** ูุณุชูุฏ
- ุงู ฺฉุงุฑ ุจู Discriminator ฺฉูฺฉ ูโฺฉูุฏ ูุฑุฒ ุจู ฺฉูุงุณโูุง ุฑุง ุจูุชุฑ ุงุฏ ุจฺฏุฑุฏ

### 2. ูุนูุงุฑ K+1 ฺฉูุงุณู
**ุงู ูููุชุฑู ูฺฺฏ ุงุณุช!**

ุฏุฑ ุงู ูพุงุฏูโุณุงุฒุ Discriminator **3 ฺฉูุงุณ** ุฏุงุฑุฏ:
- **ฺฉูุงุณ 0**: ุฏุงุฑู ุฏุงุฎู (Inner Circle) - ุฏุงุฏู ูุงูุน
- **ฺฉูุงุณ 1**: ุฏุงุฑู ุจุฑูู (Outer Circle) - ุฏุงุฏู ูุงูุน  
- **ฺฉูุงุณ 2**: ุฏุงุฏู ุชููุฏ (Fake/Generated)

**ฺุฑุง ุงู ููู ุงุณุชุ**
1. โ Generator ูุฌุจูุฑ ูโุดูุฏ ุฏุงุฏูโูุง ุชููุฏ ฺฉูุฏ ฺฉู ุฏุฑ **ูุฑุฒ ุจู ุฏู ฺฉูุงุณ ูุงูุน** ูุฑุงุฑ ฺฏุฑูุฏ
2. โ Discriminator ููโุชูุงูุฏ ุจู ุฑุงุญุช ุฏุงุฏู ุชููุฏ ุฑุง ุจู ฺฉ ุงุฒ ฺฉูุงุณโูุง ูุงูุน ูุณุจุช ุฏูุฏ
3. โ ููโูพูุดุงู ฺฉูุชุฑ ุจู ุฏุงุฏูโูุง ูุงูุน ู ุชููุฏ ูุฌูุฏ ุฏุงุฑุฏ
4. โ ูุฏู Semi-Supervised ุจูุชุฑ ฺฉุงุฑ ูโฺฉูุฏ

### 3. Conditional Entropy - ฺฉูุฏโุชุฑู ุชฺฉูฺฉ
```python
# ูุญุงุณุจู: -sum p(k|x) log p(k|x) ุจุฑุง k <= K
cond_ent_loss = -mean(sum(unl_probs * log(unl_probs)))
```

**ฺุฑุง ููู ุงุณุชุ**
- ุจุฏูู ุงู lossุ discriminator ููฺฉู ุงุณุช **uncertain** ุจุงุดุฏ
- ููฺฉู ุงุณุช ุงุญุชูุงูุงุช ฺฉุณุงู ุจู ููู ฺฉูุงุณโูุง ุจุฏูุฏ (ูุซูุงู 0.33, 0.33, 0.33)
- Conditional Entropy ุงู ุฑุง ุฌุฑูู ูโฺฉูุฏ ู discriminator ุฑุง ูุฌุจูุฑ ูโฺฉูุฏ **ุจุง ุงุทููุงู** ูพุดโุจู ฺฉูุฏ
- ูุซูุงู: (0.9, 0.05, 0.05) โ Entropy ฺฉู โ ุฎูุจ
- ูุซูุงู: (0.33, 0.33, 0.33) โ Entropy ุจุงูุง โ ุจุฏ

**ุดุฑุท ููุงูู**: "Strong True-Fake Belief" - ูุฏู ุจุงุฏ ุจุง ุงุทููุงู ุจุงูุง ุชุตูู ุจฺฏุฑุฏ

### 4. ูุญูู ูุญุงุณุจู Loss
- **ุจุฑุง ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑ**: ููุท ุงุฒ 2 ฺฉูุงุณ ุงูู ุงุณุชูุงุฏู ูโุดูุฏ (Fake class ูุงุฏุฏู ฺฏุฑูุชู ูโุดูุฏ)
- **ุจุฑุง ุฏุงุฏูโูุง ูุงูุน ุจุฏูู ุจุฑฺุณุจ**: ุจุงุฏ ุจู ฺฉ ุงุฒ 2 ฺฉูุงุณ ุงูู ูุณุจุช ุฏุงุฏู ุดููุฏ (ูู Fake)
- **ุจุฑุง ุฏุงุฏูโูุง ุชููุฏ**: ุจุงุฏ ุญุชูุงู ุจู ฺฉูุงุณ Fake (ฺฉูุงุณ 2) ูุณุจุช ุฏุงุฏู ุดููุฏ

### 5. ูุนุงุฑ ููููุช
- `lab_acc` ุจุงุฏ ุจู ุจุงูุง 90% ุจุฑุณุฏ (ุฏูุช ุทุจููโุจูุฏ)
- `unl_acc` ุจุงุฏ ุจู ุจุงูุง 85% ุจุฑุณุฏ (ุฏุงุฏู ูุงูุน ุจู ุนููุงู real ุดูุงุฎุชู ุดูุฏ)
- `gen_acc` ุจุงุฏ ุจู ุจุงูุง 70% ุจุฑุณุฏ (ุฏุงุฏู ุชููุฏ ุจู ุนููุงู fake ุดูุงุฎุชู ุดูุฏ)
- **`cond_ent_loss`** ุจุงุฏ ุจู ุชุฏุฑุฌ ฺฉุงูุด ุงุจุฏ (ูุดุงูโุฏููุฏู ุงุทููุงู ุจุงูุง discriminator)

### 6. ุชูุธู ูพุงุฑุงูุชุฑูุง ุจุฑุง ุขุฒูุงุด

ูโุชูุงูุฏ ุชุฃุซุฑ ูุฑ ุชฺฉูฺฉ ุฑุง ุจู ุตูุฑุช ุฌุฏุงฺฏุงูู ุจุฑุฑุณ ฺฉูุฏ:

```python
# ุขุฒูุงุด 1: ููุท ุจุง Feature Matching
use_conditional_entropy = False
use_feature_matching = True
use_pull_away = False
use_complement_generator = False
use_vi_entropy = False

# ุขุฒูุงุด 2: ููุท ุจุง Conditional Entropy (ุชูุตู ููุงูู)
use_conditional_entropy = True
use_feature_matching = False
use_pull_away = False
use_complement_generator = False
use_vi_entropy = False

# ุขุฒูุงุด 3: ููู ุชฺฉูฺฉโูุง ุงุตู (ุจูุชุฑู ูุชุฌู)
use_conditional_entropy = True
use_feature_matching = True
use_pull_away = True
use_complement_generator = False
use_vi_entropy = False

# ุขุฒูุงุด 4: ุจุง Complement Generator (KDE)
use_conditional_entropy = True
use_feature_matching = True
use_pull_away = True
use_complement_generator = True  # ูุนุงู
density_weight = 0.5
use_vi_entropy = False

# ุขุฒูุงุด 5: ุจุง VI Entropy
use_conditional_entropy = True
use_feature_matching = True
use_pull_away = True
use_complement_generator = False
use_vi_entropy = True  # ูุนุงู
vi_weight = 0.1

# ุขุฒูุงุด 6: ููู ฺุฒ ูุนุงู (ูพฺุฏู - ุจุฑุง ุชุญูู)
use_conditional_entropy = True
use_feature_matching = True
use_pull_away = True
use_complement_generator = True
use_vi_entropy = True
```

**ุชูุตู**: ุงุจุชุฏุง ุจุง ุขุฒูุงุด 3 ุดุฑูุน ฺฉูุฏุ ุณูพุณ ุชฺฉูฺฉโูุง ูพุดุฑูุชู ุฑุง ุงูุชุญุงู ฺฉูุฏ.

### 7. ุชุดุฎุต GPU/CPU
ฺฉุฏ ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ GPU ุฑุง ุชุดุฎุต ูโุฏูุฏ:
```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

### 8. Learning Rate Decay
Learning rate ุจู ุตูุฑุช ุฎุท ฺฉุงูุด ูโุงุจุฏ:
```python
lr = initial_lr * min(3 * (1 - epoch_ratio), 1)
```

### 9. ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑ
- ููุท 40 ููููู ุงุฒ 2000 ููููู ุจุฑฺุณุจ ุฏุงุฑูุฏ (2%)
- 20 ููููู ุงุฒ ฺฉูุงุณ 0 (ุฏุงุฑู ุฏุงุฎู)
- 20 ููููู ุงุฒ ฺฉูุงุณ 1 (ุฏุงุฑู ุจุฑูู)

### 10. ูุญูู ุชููุฏ ุฏุงุฏู
ุฏุงุฏูโูุง ุจุง ุงุณุชูุงุฏู ุงุฒ `sklearn.datasets.make_circles` ุชููุฏ ูโุดููุฏ:
- `n_samples`: 2000 ููููู ุจุฑุง trainุ 1000 ููููู ุจุฑุง test
- `noise`: 0.05 (ูุฒุงู ููุฒ)
- `factor`: 0.5 (ูุณุจุช ุดุนุงุน ุฏุงุฑู ุฏุงุฎู ุจู ุจุฑูู)

### 11. ูุฏู ุขููุฒุด
- **Generator**: ุชููุฏ ููุงุท 2D ฺฉู:
  - ูพุฑุงฺฉูุฏฺฏ ุดุจู ุฏู ุฏุงุฑู ูุชุญุฏุงููุฑฺฉุฒ ุฏุงุดุชู ุจุงุดูุฏ
  - ุฏุฑ ูุฑุฒ ุจู ุฏู ฺฉูุงุณ ูุฑุงุฑ ฺฏุฑูุฏ (ูู ุฏููุงู ุฑู ฺฉ ุงุฒ ุฏุงุฑูโูุง)
- **Discriminator**: 
  - ุชุดุฎุต ุฏุงุฏู ูุงูุน ุงุฒ ุชููุฏ (ฺฉูุงุณ Fake)
  - ุทุจููโุจูุฏ ุฏูู ุฏุงุฏูโูุง ูุงูุน ุจุง ุชุนุฏุงุฏ ฺฉู ุฏุงุฏู ุจุฑฺุณุจโุฏุงุฑ
  - ุดูุงุณุง ุฏุงุฏูโูุง ุชููุฏ ุจู ุนููุงู ฺฉูุงุณ ุฌุฏุงฺฏุงูู

### 12. ุชูุงูุช ุจุง ูพุงุฏูโุณุงุฒโูุง ูุนููู GAN

**GAN ูุนููู**:
- ูุฏู: Generator ฺฉุงูู ฺฉู ุฏููุงู ูุซู ุฏุงุฏู ูุงูุน ุชููุฏ ฺฉูุฏ
- Discriminator ููุท Real/Fake ุชุดุฎุต ูโุฏูุฏ (2 ุฎุฑูุฌ)
- ุจุฏูู ุงุณุชูุงุฏู ุงุฒ ุฏุงุฏู ุจุฏูู ุจุฑฺุณุจ ุจุฑุง classification

**Bad GAN (ุงู ูพุงุฏูโุณุงุฒ)**:
- ูุฏู: Generator "ูููโุฎูุจ" ฺฉู ุฏุฑ ูุฑุฒูุง ุจู ฺฉูุงุณโูุง ุชููุฏ ฺฉูุฏ
- Discriminator ุจุง K+1 ฺฉูุงุณ (2 real + 1 fake)
- Conditional Entropy ุจุฑุง ุงุทููุงู ุจุงูุง
- ุงุณุชูุงุฏู ุงุฒ ุฏุงุฏู ุจุฏูู ุจุฑฺุณุจ ุจุฑุง ุจูุจูุฏ classification
- Feature Matching ู Pull-away Term ุจุฑุง ฺฉูุชุฑู Generator

## ๐ ูุนุงุฑูุง ููููุช

### 1. ุฏูุช ุทุจููโุจูุฏ
- ุฑู ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑ: ุจุงุฏ ุจู ุจุงูุง 90% ุจุฑุณุฏ
- ุฑู ุฏุงุฏูโูุง ุชุณุช: ุจุงุฏ ุจู ุจุงูุง 85% ุจุฑุณุฏ

### 2. ฺฉูุช ุชููุฏ ู ุชุดุฎุต Fake
- ุฏุงุฏูโูุง ุชููุฏ ุจุงุฏ ุฏุฑ ูุฑุฒ ุจู ุฏู ุฏุงุฑู ูุชุญุฏุงููุฑฺฉุฒ ูุฑุงุฑ ฺฏุฑูุฏ
- ุชููุน ุฏุฑ ุฏุงุฏูโูุง ุชููุฏ (ูุฑ ุฏู ุฏุงุฑู ูพูุดุด ุฏุงุฏู ุดููุฏ)
- **ููู**: Discriminator ุจุงุฏ ุญุฏุงูู 70% ุงุฒ ุฏุงุฏูโูุง ุชููุฏ ุฑุง ุจู ุนููุงู Fake ุชุดุฎุต ุฏูุฏ

### 3. ุชูุงุฒู GAN
- `lab_acc` ุจุงุฏ ุจู ุชุฏุฑุฌ ุจู 0.9-1.0 ุจุฑุณุฏ
- `unl_acc` ุจุงุฏ ุจู ุชุฏุฑุฌ ุจู 0.8-0.95 ุจุฑุณุฏ (ุฏุงุฏู ูุงูุน ุจู ุนููุงู real)
- `gen_acc` ุจุงุฏ ุงุฒ 0 ุดุฑูุน ฺฉูุฏ ู ุจู 0.7-0.9 ุจุฑุณุฏ (ุฏุงุฏู ุชููุฏ ุจู ุนููุงู fake)

### 4. ูููุนุช ุฏุงุฏูโูุง ุชููุฏ
ุฏุฑ ูููุฏุงุฑูุงุ ุฏุงุฏูโูุง ุชููุฏ ุจุงุฏ:
- โ ุฏุฑ ูุฑุฒ ุจู ุฏู ุฏุงุฑู ุธุงูุฑ ุดููุฏ
- โ ุจุดุชุฑ ุจู ุฑูฺฏ ุณุจุฒ ููู (โญ Fake class) ุจุงุดูุฏ
- โ ูุจุงุฏ ูููพูุดุงู ุฒุงุฏ ุจุง ุฏุงุฑูโูุง ุงุตู ุฏุงุดุชู ุจุงุดูุฏ

## ๐ ุนุจโุงุจ

### ูุดฺฉู: GPU ูพุฏุง ููโุดูุฏ
**ุฑุงูโุญู**: ฺฉุฏ ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ ุฑู CPU ุงุฌุฑุง ูโุดูุฏ. ุจุฑุง ุงุณุชูุงุฏู ุงุฒ GPUุ CUDA ู PyTorch ุจุง ูพุดุชุจุงู CUDA ูุตุจ ฺฉูุฏ.

### ูุดฺฉู: Mode Collapse (Generator ููุท ฺฉ ููุน ุฏุงุฏู ุชููุฏ ูโฺฉูุฏ)
**ุฑุงูโุญู**: ุงูุฒุงุด `pt_weight` ุฏุฑ config

### ูุดฺฉู: ุฏูุช ูพุงู ุทุจููโุจูุฏ
**ุฑุงูโุญู**: 
- ุงูุฒุงุด `max_epochs`
- ฺฉุงูุด `learning_rate`
- ุงูุฒุงุด `size_labeled_data`

### ูุดฺฉู: Generator ุฏุงุฏูโูุง ุฑู ุฏุงุฑูโูุง ุงุตู ุชููุฏ ูโฺฉูุฏ (ูู ุฏุฑ ูุฑุฒ)
**ุฑุงูโุญู**:
- ุงู ุฑูุชุงุฑ **ุงุดุชุจุงู** ุงุณุช! ุจุฑุฑุณ ฺฉูุฏ ฺฉู `gen_acc` (ูุฑุฎ ุชุดุฎุต Fake) ุจู ุจุงูุง 70% ูโุฑุณุฏ
- ุงฺฏุฑ `gen_acc` ูพุงู ุงุณุชุ ูุฒู `fake_loss` ุฑุง ุงูุฒุงุด ุฏูุฏ
- ุจุฑุฑุณ ฺฉูุฏ ฺฉู Discriminator ูุงูุนุงู 3 ฺฉูุงุณ ุฏุงุฑุฏ (ูู 2)

### ูุดฺฉู: ุฏุงุฏูโูุง ูุงูุน ุจู ุนููุงู Fake ุดูุงุณุง ูโุดููุฏ
**ุฑุงูโุญู**:
- ุจุฑุฑุณ ฺฉูุฏ ฺฉู `unl_acc` ุจุงูุง 85% ุงุณุช
- ฺฉุงูุด learning rate
- ุงูุฒุงุด ุชุนุฏุงุฏ ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑ

### ูุดฺฉู: ุชูุงู ุชฺฉูฺฉโูุง ูพุดุฑูุชู ูุนุงู ูุณุชูุฏ ูู training ูุงูพุงุฏุงุฑ ุงุณุช
**ุฑุงูโุญู**:
- ุงุจุชุฏุง ููุท ุจุง ุชฺฉูฺฉโูุง ุงุตู ุดุฑูุน ฺฉูุฏ (FM + PT + Cond Ent)
- ุจุนุฏ ฺฉโฺฉ ุชฺฉูฺฉโูุง ูพุดุฑูุชู ุฑุง ุงุถุงูู ฺฉูุฏ
- ูุฒูโูุง ุฑุง ฺฉุงูุด ุฏูุฏ: `density_weight=0.3`, `vi_weight=0.05`
- Learning rate ุฑุง ฺฉู ฺฉูุฏ

### ูุดฺฉู: KDE training ุฎู ุทูู ูโฺฉุดุฏ
**ุฑุงูโุญู**:
- ุชุนุฏุงุฏ ูููููโูุง ุจุฑุง KDE ุฑุง ฺฉู ฺฉูุฏ (ุฏุฑ ฺฉุฏ: `if i >= 50` โ `if i >= 20`)
- bandwidth ุฑุง ุงูุฒุงุด ุฏูุฏ: `bandwidth=0.2`

### ูุดฺฉู: VI entropy ุจุงุนุซ mode collapse ูโุดูุฏ
**ุฑุงูโุญู**:
- `vi_weight` ุฑุง ฺฉุงูุด ุฏูุฏ: `0.05` ุง `0.03`
- Pull-away term ุฑุง ูุนุงู ูฺฏู ุฏุงุฑุฏ (ูุฑ ุฏู ุจุง ูู ฺฉุงุฑ ูโฺฉููุฏ)
- ุจุฑุฑุณ ฺฉูุฏ ฺฉู Encoder ุฏุฑุณุช initialize ุดุฏู ุจุงุดุฏ

## ๐ ูุฑุงุฌุน

ุงู ฺฉุฏ ุจุฑ ุงุณุงุณ ููุงูุงุช ุฒุฑ ูพุงุฏูโุณุงุฒ ุดุฏู:

### ููุงูู ุงุตู: Bad GAN
**"Good Semi-supervised Learning That Requires a Bad GAN"**
- Dai et al., NIPS 2017
- arXiv: [1705.09783](https://arxiv.org/abs/1705.09783)

**ุงุฏู ฺฉูุฏ**: ฺฉ Generator ุนุงู (ฺฉู ุฏููุงู ูุงููุฏ ุฏุงุฏู ูุงูุน ุชููุฏ ูโฺฉูุฏ) ุจุฑุง Semi-Supervised Learning ููุฏ ูุณุช! ูุง ุจู ฺฉ **"Complement Generator"** ูุงุฒ ุฏุงุฑู ฺฉู ูููููโูุง ุฏุฑ **ููุงุทู ฺฉูโุชุฑุงฺฉู** (ูุฑุฒูุง ุจู ฺฉูุงุณโูุง) ุชููุฏ ฺฉูุฏ.

**ุชูุงูุช ุจุง GAN ูุนููู**:
- GAN ูุนููู: ูุฏู Generator ุงู ุงุณุช ฺฉู Discriminator ุฑุง ูุฑุจ ุฏูุฏ
- Bad GAN: ูุฏู Generator ุงู ุงุณุช ฺฉู ูููููโูุง ุฏุฑ ูุฑุฒูุง ุจู ฺฉูุงุณโูุง ุชููุฏ ฺฉูุฏ

**ุชฺฉูฺฉโูุง ุงุตู ุงุฒ ุงู ููุงูู ฺฉู ูพุงุฏูโุณุงุฒ ุดุฏู**:
1. โ **Conditional Entropy Loss** (ูููโุชุฑู): Discriminator ุจุงุฏ ุฑู ูพุดโุจูโูุง ุฎูุฏ ุจุฑุง ฺฉูุงุณโูุง ูุงูุน ุงุทููุงู ุจุงูุง ุฏุงุดุชู ุจุงุดุฏ
2. โ **K+1 Class Architecture**: ฺฉูุงุณ ุฌุฏุงฺฏุงูู ุจุฑุง Fake samples
3. โ **Feature Matching**: Generator ุงุฒ ููุงุณู feature statistics ุงุณุชูุงุฏู ูโฺฉูุฏ
4. โ **Pull-away Term**: ุงูุฒุงุด ุชููุน ุฏุฑ ูููููโูุง ุชููุฏ

**ุชฺฉูฺฉโูุง ูพุดุฑูุชู ุงุถุงูู ุดุฏู**:
5. โ **KDE-based Complement Generator**: ุชููุฏ ุฏุฑ ููุงุทู ฺฉูโุชุฑุงฺฉู ุจุง Kernel Density Estimation
6. โ **VI-based Entropy Maximization**: ุงูุฒุงุด ุชููุน ุฏุฑ latent space ุจุง Variational Inference

### ููุงูุงุช ูุฑุชุจุท
- **"Improved Techniques for Training GANs"** (Salimans et al., NIPS 2016)
  - Feature Matching ู Pull-away Term ุงุฒ ุงู ููุงูู
  - K+1 class formulation ุจุฑุง Semi-Supervised GANs

- **"Semi-Supervised Learning with Deep Generative Models"** (Kingma et al., NIPS 2014)
  - Variational Inference ุจุฑุง SSL

## ๐ ุงุฏุฏุงุดุชโูุง ุชูุณุนู

### ุชูุงูุช ุจุง MNIST
- ุจุฏูู PixelCNN (ฺูู ุชุตูุฑ ูุณุช)
- ูุนูุงุฑ ุณุงุฏูโุชุฑ (MLP ุจู ุฌุง CNN)
- ุฏุงุฏู 2D ุจู ุฌุง ุชุตุงูุฑ 28ร28

### ุชูุงูุช ุจุง ุฏุชุงุณุชโูุง ุฏฺฏุฑ
- ุจุฏูู Encoder ุฏุฑ loss function (ุงฺฏุฑฺู ูุนูุงุฑ ููุฌูุฏ ุงุณุช)
- ุฑู ุฏุงุฏูโูุง 2D ุจู ุฌุง ุชุตุงูุฑ RGB
- **ุฏุงุฑุง ฺฉูุงุณ ุฌุฏุงฺฏุงูู Fake** (3 ฺฉูุงุณ: inner, outer, fake)

## โ ุฎูุงุตู

ุงู ูพุฑูฺู ูููููโุง ุงุฒ **Semi-Supervised Learning ุจุง Bad GAN** ุงุณุช ฺฉู:

### ููุงูู ูพุงู
- **"Good Semi-supervised Learning That Requires a Bad GAN"** (Dai et al., NIPS 2017)
- ุงุฏู ฺฉูุฏ: Generator ูุจุงุฏ ฺฉุงูู ุจุงุดุฏุ ุจูฺฉู ุจุงุฏ "Complement Generator" ุจุงุดุฏ

### ูฺฺฏโูุง ุงุตู
- ุจุง ุชุนุฏุงุฏ ุจุณุงุฑ ฺฉู ุฏุงุฏู ุจุฑฺุณุจโุฏุงุฑ (40 ููููู = 2%) ุขููุฒุด ูโุจูุฏ
- ุงุฒ ุฏุงุฏูโูุง ุจุฏูู ุจุฑฺุณุจ (2000 ููููู) ุจุฑุง ุจูุจูุฏ ุงุณุชูุงุฏู ูโฺฉูุฏ
- **ุงุฒ ูุนูุงุฑ K+1 ฺฉูุงุณู ุงุณุชูุงุฏู ูโฺฉูุฏ** (ฺฉูุงุณ ุฌุฏุงฺฏุงูู ุจุฑุง Fake)
- ูุงุฏุฑ ุจู ุชููุฏ ุฏุงุฏูโูุง ุฌุฏุฏ ุฏุฑ ูุฑุฒ ุจู ฺฉูุงุณโูุง ุงุณุช

### ุชฺฉูฺฉโูุง ูพุงุฏูโุณุงุฒ ุดุฏู ุงุฒ ููุงูู
1. โ **Conditional Entropy Loss** - ฺฉูุฏโุชุฑู ุชฺฉูฺฉ
2. โ **Feature Matching** - ุจุฑุง ูุฏุงุช Generator
3. โ **Pull-away Term** - ุจุฑุง ุชููุน ู ุฌููฺฏุฑ ุงุฒ mode collapse
4. โ **K+1 Class Architecture** - ุจุฑุง Semi-Supervised GAN

### ูุงุจูุชโูุง ูพุดุฑูุชู (ูพุงุฏูโุณุงุฒ ุดุฏู - ุงุฎุชุงุฑ)
- โ **KDE-based Complement Generator**: ุงุณุชูุงุฏู ุงุฒ Kernel Density Estimation ุจุฑุง ุชุฎูู ฺฺฏุงู ู ุชููุฏ ุฏุฑ ููุงุทู ฺฉูโุชุฑุงฺฉู
  - ููุงุณุจ ุจุฑุง ุฏุงุฏูโูุง 2D
  - ุณุจฺฉโุชุฑ ุงุฒ PixelCNN
  - ูุงุจู ูุนุงูโุณุงุฒ ุจุง `use_complement_generator = True`
  
- โ **VI-based Entropy Maximization**: ุงุณุชูุงุฏู ุงุฒ Encoder ู Variational Inference ุจุฑุง ุงูุฒุงุด ุชููุน ุฏุฑ latent space
  - ูุญุงุณุจู KL divergence ุงุฒ prior
  - ุชุถูู coverage ุจูุชุฑ ุงุฒ data distribution
  - ูุงุจู ูุนุงูโุณุงุฒ ุจุง `use_vi_entropy = True`

### ูุชุงุฌ ููุฑุฏ ุงูุชุธุงุฑ
- ุฏูุช ุทุจููโุจูุฏ ุจุงูุง (>90%)
- ุฏุงุฏูโูุง ุชููุฏ ุฏุฑ ูุฑุฒ ุจู ฺฉูุงุณโูุง
- ูููุฏุงุฑูุง ุฏูู ู ูุงุถุญ ุจุฑุง ุฏุฑฺฉ ุนููฺฉุฑุฏ
- ุจุง ุชฺฉูฺฉโูุง ูพุดุฑูุชู: ุชููุน ุจุดุชุฑ ู coverage ุจูุชุฑ

**ูฺฉุชู ููู**: ูุฏู ุงู ูุณุช ฺฉู Generator ฺฉุงูู ุจุงุดุฏ! ูุฏู ุงู ุงุณุช ฺฉู Generator ูููููโูุง ุฏุฑ **ููุงุทู ฺฉูโุชุฑุงฺฉู** (ูุฑุฒูุง ุจู ฺฉูุงุณโูุง) ุชููุฏ ฺฉูุฏ ุชุง ุจู Discriminator ุฏุฑ ุงุฏฺฏุฑ ูุฑุฒ ุจู ฺฉูุงุณโูุง ฺฉูฺฉ ฺฉูุฏ. ุงู ููุงู ฺุฒ ุงุณุช ฺฉู ููุงูู "Bad GAN" ุขู ุฑุง ูุดุงู ุฏุงุฏู ุงุณุช.

### ููุงุณู ุจุง ุฑูุดโูุง ุฏฺฏุฑ
| ุฑูุด | Generator | ุชุฃุซุฑ ุฑู SSL | ูุชุฌู |
|-----|-----------|---------------|-------|
| **Supervised ููุท** | - | - | ุฎูุจ ุงูุง ูุญุฏูุฏ ุจู ุฏุงุฏู ุจุฑฺุณุจโุฏุงุฑ |
| **GAN ูุนููู** | ฺฉุงูู (p_G = p) | โ ุจโูุงุฏู | ูุซู Supervised |
| **Bad GAN** | Complement (ุฏุฑ ูุฑุฒูุง) | โ ููุฏ | ุจูุชุฑู ูุชุฌู ุจุง ุฏุงุฏู ฺฉู |
